{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkNet: A Keras implementation for the Kaggle Carvana Image Masking Challenge \n",
    "\n",
    "\n",
    "Date created: Dec 20, 2017   \n",
    "Last modified: Jan 19, 2018  \n",
    "Tags: LinkNet, Keras, semantic segmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:49:43.585829Z",
     "start_time": "2017-09-04T16:48:25.759269Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from keras.layers import Input, Activation, BatchNormalization, concatenate\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "import linknet\n",
    "import losses\n",
    "import augmentation\n",
    "\n",
    "DATAPATH = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:49:45.675212Z",
     "start_time": "2017-09-04T16:49:43.642003Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "initial__conv (Conv2D)          (None, 256, 256, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "initial__bn (BatchNormalization (None, 256, 256, 64) 256         initial__conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "initial_act (Activation)        (None, 256, 256, 64) 0           initial__bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           initial_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1a_conv (Conv2D)      (None, 64, 64, 64)   36928       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1a_bn (BatchNormaliza (None, 64, 64, 64)   256         encoder_1_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1a_act (Activation)   (None, 64, 64, 64)   0           encoder_1_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1b_conv (Conv2D)      (None, 64, 64, 64)   36928       encoder_1_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1b_shortcut (Conv2D)  (None, 64, 64, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1b_bn (BatchNormaliza (None, 64, 64, 64)   256         encoder_1_1b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           encoder_1_1b_shortcut[0][0]      \n",
      "                                                                 encoder_1_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1b_act (Activation)   (None, 64, 64, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_2a_conv (Conv2D)      (None, 64, 64, 64)   36928       encoder_1_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_2a_bn (BatchNormaliza (None, 64, 64, 64)   256         encoder_1_2a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_2a_act (Activation)   (None, 64, 64, 64)   0           encoder_1_2a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_2b_conv (Conv2D)      (None, 64, 64, 64)   36928       encoder_1_2a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_2b_bn (BatchNormaliza (None, 64, 64, 64)   256         encoder_1_2b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           encoder_1_1b_act[0][0]           \n",
      "                                                                 encoder_1_2b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_2b_act (Activation)   (None, 64, 64, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1a_conv (Conv2D)      (None, 32, 32, 128)  73856       encoder_1_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1a_bn (BatchNormaliza (None, 32, 32, 128)  512         encoder_2_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1a_act (Activation)   (None, 32, 32, 128)  0           encoder_2_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1b_conv (Conv2D)      (None, 32, 32, 128)  147584      encoder_2_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1b_shortcut (Conv2D)  (None, 32, 32, 128)  8320        encoder_1_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1b_bn (BatchNormaliza (None, 32, 32, 128)  512         encoder_2_1b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           encoder_2_1b_shortcut[0][0]      \n",
      "                                                                 encoder_2_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1b_act (Activation)   (None, 32, 32, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_2a_conv (Conv2D)      (None, 32, 32, 128)  147584      encoder_2_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_2a_bn (BatchNormaliza (None, 32, 32, 128)  512         encoder_2_2a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_2a_act (Activation)   (None, 32, 32, 128)  0           encoder_2_2a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_2b_conv (Conv2D)      (None, 32, 32, 128)  147584      encoder_2_2a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_2b_bn (BatchNormaliza (None, 32, 32, 128)  512         encoder_2_2b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 128)  0           encoder_2_1b_act[0][0]           \n",
      "                                                                 encoder_2_2b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_2b_act (Activation)   (None, 32, 32, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1a_conv (Conv2D)      (None, 16, 16, 256)  295168      encoder_2_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1a_bn (BatchNormaliza (None, 16, 16, 256)  1024        encoder_3_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1a_act (Activation)   (None, 16, 16, 256)  0           encoder_3_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1b_conv (Conv2D)      (None, 16, 16, 256)  590080      encoder_3_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1b_shortcut (Conv2D)  (None, 16, 16, 256)  33024       encoder_2_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1b_bn (BatchNormaliza (None, 16, 16, 256)  1024        encoder_3_1b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           encoder_3_1b_shortcut[0][0]      \n",
      "                                                                 encoder_3_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1b_act (Activation)   (None, 16, 16, 256)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_2a_conv (Conv2D)      (None, 16, 16, 256)  590080      encoder_3_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_2a_bn (BatchNormaliza (None, 16, 16, 256)  1024        encoder_3_2a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_2a_act (Activation)   (None, 16, 16, 256)  0           encoder_3_2a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_2b_conv (Conv2D)      (None, 16, 16, 256)  590080      encoder_3_2a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_2b_bn (BatchNormaliza (None, 16, 16, 256)  1024        encoder_3_2b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 256)  0           encoder_3_1b_act[0][0]           \n",
      "                                                                 encoder_3_2b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_2b_act (Activation)   (None, 16, 16, 256)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1a_conv (Conv2D)      (None, 8, 8, 512)    1180160     encoder_3_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1a_bn (BatchNormaliza (None, 8, 8, 512)    2048        encoder_4_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1a_act (Activation)   (None, 8, 8, 512)    0           encoder_4_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1b_conv (Conv2D)      (None, 8, 8, 512)    2359808     encoder_4_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1b_shortcut (Conv2D)  (None, 8, 8, 512)    131584      encoder_3_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1b_bn (BatchNormaliza (None, 8, 8, 512)    2048        encoder_4_1b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 512)    0           encoder_4_1b_shortcut[0][0]      \n",
      "                                                                 encoder_4_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1b_act (Activation)   (None, 8, 8, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_2a_conv (Conv2D)      (None, 8, 8, 512)    2359808     encoder_4_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_2a_bn (BatchNormaliza (None, 8, 8, 512)    2048        encoder_4_2a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_2a_act (Activation)   (None, 8, 8, 512)    0           encoder_4_2a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_2b_conv (Conv2D)      (None, 8, 8, 512)    2359808     encoder_4_2a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_2b_bn (BatchNormaliza (None, 8, 8, 512)    2048        encoder_4_2b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 512)    0           encoder_4_1b_act[0][0]           \n",
      "                                                                 encoder_4_2b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_2b_act (Activation)   (None, 8, 8, 512)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1a_conv (Conv2D)      (None, 8, 8, 128)    65664       encoder_4_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1a_bn (BatchNormaliza (None, 8, 8, 128)    512         decoder_4_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1a_act (Activation)   (None, 8, 8, 128)    0           decoder_4_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1b_fullconv (Conv2DTr (None, 16, 16, 128)  147584      decoder_4_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1b_bn (BatchNormaliza (None, 16, 16, 128)  512         decoder_4_1b_fullconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1b_act (Activation)   (None, 16, 16, 128)  0           decoder_4_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1c_conv (Conv2D)      (None, 16, 16, 256)  33024       decoder_4_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1c_bn (BatchNormaliza (None, 16, 16, 256)  1024        decoder_4_1c_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1c_act (Activation)   (None, 16, 16, 256)  0           decoder_4_1c_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 512)  0           decoder_4_1c_act[0][0]           \n",
      "                                                                 encoder_3_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1a_conv (Conv2D)      (None, 16, 16, 64)   32832       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1a_bn (BatchNormaliza (None, 16, 16, 64)   256         decoder_3_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1a_act (Activation)   (None, 16, 16, 64)   0           decoder_3_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1b_fullconv (Conv2DTr (None, 32, 32, 64)   36928       decoder_3_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1b_bn (BatchNormaliza (None, 32, 32, 64)   256         decoder_3_1b_fullconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1b_act (Activation)   (None, 32, 32, 64)   0           decoder_3_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1c_conv (Conv2D)      (None, 32, 32, 128)  8320        decoder_3_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1c_bn (BatchNormaliza (None, 32, 32, 128)  512         decoder_3_1c_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1c_act (Activation)   (None, 32, 32, 128)  0           decoder_3_1c_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 256)  0           decoder_3_1c_act[0][0]           \n",
      "                                                                 encoder_2_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1a_conv (Conv2D)      (None, 32, 32, 32)   8224        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1a_bn (BatchNormaliza (None, 32, 32, 32)   128         decoder_2_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1a_act (Activation)   (None, 32, 32, 32)   0           decoder_2_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1b_fullconv (Conv2DTr (None, 64, 64, 32)   9248        decoder_2_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1b_bn (BatchNormaliza (None, 64, 64, 32)   128         decoder_2_1b_fullconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1b_act (Activation)   (None, 64, 64, 32)   0           decoder_2_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1c_conv (Conv2D)      (None, 64, 64, 64)   2112        decoder_2_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1c_bn (BatchNormaliza (None, 64, 64, 64)   256         decoder_2_1c_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1c_act (Activation)   (None, 64, 64, 64)   0           decoder_2_1c_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 128)  0           decoder_2_1c_act[0][0]           \n",
      "                                                                 encoder_1_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1a_conv (Conv2D)      (None, 64, 64, 16)   2064        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1a_bn (BatchNormaliza (None, 64, 64, 16)   64          decoder_1_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1a_act (Activation)   (None, 64, 64, 16)   0           decoder_1_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1b_fullconv (Conv2DTr (None, 128, 128, 16) 2320        decoder_1_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1b_bn (BatchNormaliza (None, 128, 128, 16) 64          decoder_1_1b_fullconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1b_act (Activation)   (None, 128, 128, 16) 0           decoder_1_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1c_conv (Conv2D)      (None, 128, 128, 64) 1088        decoder_1_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1c_bn (BatchNormaliza (None, 128, 128, 64) 256         decoder_1_1c_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1c_act (Activation)   (None, 128, 128, 64) 0           decoder_1_1c_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "final_1_fullconv (Conv2DTranspo (None, 256, 256, 32) 18464       decoder_1_1c_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "final_1_bn (BatchNormalization) (None, 256, 256, 32) 128         final_1_fullconv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "final__1_act (Activation)       (None, 256, 256, 32) 0           final_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "final_2_conv (Conv2D)           (None, 256, 256, 32) 9248        final__1_act[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_2_bn (BatchNormalization) (None, 256, 256, 32) 128         final_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final__2_act (Activation)       (None, 256, 256, 32) 0           final_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "final_3_fullconv (Conv2DTranspo (None, 512, 512, 1)  129         final__2_act[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 262144)    0           final_3_fullconv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 262144, 1)    0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 262144, 1)    0           permute_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,572,961\n",
      "Trainable params: 11,563,041\n",
      "Non-trainable params: 9,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = linknet.build_LinkNet(input_shape=(512,512, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data, Preprocessing, Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "The training dataset consists of 5088 images. Each car is presented in 16 fixed photo angles. The ground truth training mask images were converted from *.gif* to *.png* format so as to be compatible with the *OpenCV* library. \n",
    "\n",
    "The images and ground truth masks can be found in the *train* and *train_masks* folders respectively. The test data was not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:50:34.627786Z",
     "start_time": "2017-09-04T16:50:33.936807Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATAPATH+'/train_masks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:50:34.647571Z",
     "start_time": "2017-09-04T16:50:34.629747Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.iloc[2:,:]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:50:35.817191Z",
     "start_time": "2017-09-04T16:50:35.810931Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_train = df_train['img'].map(lambda s: s.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:50:36.231117Z",
     "start_time": "2017-09-04T16:50:36.225000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_train_split, ids_valid_split = train_test_split(ids_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Preprocessing -- rescaling (input and mask data)\n",
    "The original image resolution of 1918 x 1280 was downsampled to 512 x 512 using the *OpenCV* library functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:50:33.348138Z",
     "start_time": "2017-09-04T16:50:33.344715Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_width = 512\n",
    "input_height = 512\n",
    "max_epochs = 10\n",
    "orig_width = 1918\n",
    "orig_height= 1280\n",
    "threshold  = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_imgs  = {}\n",
    "all_masks = {}\n",
    "\n",
    "for id in ids_train:\n",
    "    img  = cv2.imread(DATAPATH+'/train/{}.jpg'.format(id))\n",
    "    img  = cv2.resize(img, (input_width, input_height))\n",
    "    mask = cv2.imread(DATAPATH+'/train_masks_png/{}_mask.png'.format(id), cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (input_width, input_height))\n",
    "    all_imgs[id]  = img\n",
    "    all_masks[id] = mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation\n",
    "\n",
    "The following transformations using the *OpenCV* library were made:\n",
    "* Hue, Saturation, Value using randomHueSaturationValue\n",
    "* Shift, Scale, Rotate using randomShiftScaleRotate\n",
    "* Horizontal flips using randomHorizontalFlip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(train_batch_size):\n",
    "    while True:\n",
    "        this_ids_train_split = random.sample(list(ids_train_split), len(ids_train_split))\n",
    "        for start in range(0, len(ids_train_split), train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + train_batch_size, len(ids_train_split))\n",
    "            ids_train_batch = this_ids_train_split[start:end]\n",
    "            for id in ids_train_batch:\n",
    "                img  = all_imgs[id]\n",
    "                mask = all_masks[id]\n",
    "                img = augmentation.randomHueSaturationValue(img,\n",
    "                                               hue_shift_limit=(-50, 50),\n",
    "                                               sat_shift_limit=(-5, 5),\n",
    "                                               val_shift_limit=(-15, 15))\n",
    "                img, mask = augmentation.randomShiftScaleRotate(img, mask,\n",
    "                                                   shift_limit=(-0.0625, 0.0625),\n",
    "                                                   scale_limit=(-0.1, 0.1),\n",
    "                                                   rotate_limit=(-0, 0))\n",
    "                img, mask = augmentation.randomHorizontalFlip(img, mask)\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_generator(val_batch_size):\n",
    "    while True:\n",
    "        for start in range(0, len(ids_valid_split), val_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + val_batch_size, len(ids_valid_split))\n",
    "            ids_valid_batch = ids_valid_split[start:end]\n",
    "            for id in ids_valid_batch.values:\n",
    "                img  = all_imgs[id]\n",
    "                mask = all_masks[id]\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 6\n",
    "val_batch_size   = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [ReduceLROnPlateau(monitor='val_dice_coef',\n",
    "                               factor=0.2,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4,\n",
    "                               mode='max'),\n",
    "             ModelCheckpoint(monitor='val_dice_coef',\n",
    "                             filepath='../weights/best_weights_linknet_1.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='max')]\n",
    "\n",
    "history = model.fit_generator(generator=train_generator(train_batch_size),\n",
    "                    steps_per_epoch=np.ceil(float(len(ids_train_split)) / float(train_batch_size)),\n",
    "                    epochs=max_epochs,\n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_generator(val_batch_size),\n",
    "                    validation_steps=np.ceil(float(len(ids_valid_split)) / float(val_batch_size)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> References and Further Reading </h3>\n",
    "\n",
    "<a name=\"ref1\"></a>[1] [Chaurasia, Abhishek, Culurciello, Eugenio. \"LinkNet: Exploiting Encoder Representations for Efficient Semantic Segmentation.\" arXiv:1707.03718v1 [cs.CV]](https://arxiv.org/pdf/1707.03718.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FAAC58; margin-left: 0px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px;\">\n",
    "\n",
    "\n",
    "Author:  Meena Mani  <br>\n",
    "email:   meenas.mailbag@gmail.com   <br> \n",
    "Twitter: @meena_uvaca    <br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
