{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkNet: A Keras implementation for the Kaggle Carvana Image Masking Challenge \n",
    "\n",
    "\n",
    "Date created: Dec 20, 2017   \n",
    "Last modified: Jan 20, 2018  \n",
    "Tags: LinkNet, Keras, semantic segmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LinkNet <a href=\"#ref1\">[1]</a> model has been [implemented in pyTorch](https://github.com/e-lab/LinkNet). Here I have implemented a Keras version of the LinkNet. This is a sample run using data from the [Carvana Image Masking Challenge](https://www.kaggle.com/c/carvana-image-masking-challenge) on Kaggle. The top winners in this challenge had great success with both the U-Net and LinkNet models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:49:43.585829Z",
     "start_time": "2017-09-04T16:48:25.759269Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from keras.layers import Input, Activation, BatchNormalization, concatenate\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "import linknet\n",
    "import losses\n",
    "import augmentation\n",
    "\n",
    "DATAPATH = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkNet model\n",
    "\n",
    "\n",
    "The LinkNet is a symmetric encoder-decoder architecture. The four encoder/decoder blocks are connected sequentially as well as with skip/bypass connections which link an encoder with the corresponding decoder layer.\n",
    "\n",
    "**The Encoder block** uses [ResNet-18 blocks](#ref2). Each block has four 3x3 conv layers. The first of these convolutions is a *strided convolution* that downsamples the input by a factor of two. Following each convolution, *Batchnorm-ReLU* operations are performed.\n",
    "\n",
    "**The Decoder block** is lightweight. It uses 1x1 convolutions to reduce the number of parameters. A *full convoluton* (Conv2DTranspose in Keras) is used for the upsampling.\n",
    "\n",
    "The details of the network architecture are given in Section III of the [LinkNet paper](#ref1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:49:45.675212Z",
     "start_time": "2017-09-04T16:49:43.642003Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "initial__conv (Conv2D)          (None, 256, 256, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "initial__bn (BatchNormalization (None, 256, 256, 64) 256         initial__conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "initial_act (Activation)        (None, 256, 256, 64) 0           initial__bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           initial_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1a_conv (Conv2D)      (None, 64, 64, 64)   36928       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1a_bn (BatchNormaliza (None, 64, 64, 64)   256         encoder_1_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1a_act (Activation)   (None, 64, 64, 64)   0           encoder_1_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1b_conv (Conv2D)      (None, 64, 64, 64)   36928       encoder_1_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1b_shortcut (Conv2D)  (None, 64, 64, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1b_bn (BatchNormaliza (None, 64, 64, 64)   256         encoder_1_1b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           encoder_1_1b_shortcut[0][0]      \n",
      "                                                                 encoder_1_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_1b_act (Activation)   (None, 64, 64, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_2a_conv (Conv2D)      (None, 64, 64, 64)   36928       encoder_1_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_2a_bn (BatchNormaliza (None, 64, 64, 64)   256         encoder_1_2a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_2a_act (Activation)   (None, 64, 64, 64)   0           encoder_1_2a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_2b_conv (Conv2D)      (None, 64, 64, 64)   36928       encoder_1_2a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_2b_bn (BatchNormaliza (None, 64, 64, 64)   256         encoder_1_2b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           encoder_1_1b_act[0][0]           \n",
      "                                                                 encoder_1_2b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1_2b_act (Activation)   (None, 64, 64, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1a_conv (Conv2D)      (None, 32, 32, 128)  73856       encoder_1_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1a_bn (BatchNormaliza (None, 32, 32, 128)  512         encoder_2_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1a_act (Activation)   (None, 32, 32, 128)  0           encoder_2_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1b_conv (Conv2D)      (None, 32, 32, 128)  147584      encoder_2_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1b_shortcut (Conv2D)  (None, 32, 32, 128)  8320        encoder_1_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1b_bn (BatchNormaliza (None, 32, 32, 128)  512         encoder_2_1b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 128)  0           encoder_2_1b_shortcut[0][0]      \n",
      "                                                                 encoder_2_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_1b_act (Activation)   (None, 32, 32, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_2a_conv (Conv2D)      (None, 32, 32, 128)  147584      encoder_2_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_2a_bn (BatchNormaliza (None, 32, 32, 128)  512         encoder_2_2a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_2a_act (Activation)   (None, 32, 32, 128)  0           encoder_2_2a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_2b_conv (Conv2D)      (None, 32, 32, 128)  147584      encoder_2_2a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_2b_bn (BatchNormaliza (None, 32, 32, 128)  512         encoder_2_2b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 128)  0           encoder_2_1b_act[0][0]           \n",
      "                                                                 encoder_2_2b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2_2b_act (Activation)   (None, 32, 32, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1a_conv (Conv2D)      (None, 16, 16, 256)  295168      encoder_2_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1a_bn (BatchNormaliza (None, 16, 16, 256)  1024        encoder_3_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1a_act (Activation)   (None, 16, 16, 256)  0           encoder_3_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1b_conv (Conv2D)      (None, 16, 16, 256)  590080      encoder_3_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1b_shortcut (Conv2D)  (None, 16, 16, 256)  33024       encoder_2_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1b_bn (BatchNormaliza (None, 16, 16, 256)  1024        encoder_3_1b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 256)  0           encoder_3_1b_shortcut[0][0]      \n",
      "                                                                 encoder_3_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_1b_act (Activation)   (None, 16, 16, 256)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_2a_conv (Conv2D)      (None, 16, 16, 256)  590080      encoder_3_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_2a_bn (BatchNormaliza (None, 16, 16, 256)  1024        encoder_3_2a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_2a_act (Activation)   (None, 16, 16, 256)  0           encoder_3_2a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_2b_conv (Conv2D)      (None, 16, 16, 256)  590080      encoder_3_2a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_2b_bn (BatchNormaliza (None, 16, 16, 256)  1024        encoder_3_2b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 256)  0           encoder_3_1b_act[0][0]           \n",
      "                                                                 encoder_3_2b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3_2b_act (Activation)   (None, 16, 16, 256)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1a_conv (Conv2D)      (None, 8, 8, 512)    1180160     encoder_3_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1a_bn (BatchNormaliza (None, 8, 8, 512)    2048        encoder_4_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1a_act (Activation)   (None, 8, 8, 512)    0           encoder_4_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1b_conv (Conv2D)      (None, 8, 8, 512)    2359808     encoder_4_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1b_shortcut (Conv2D)  (None, 8, 8, 512)    131584      encoder_3_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1b_bn (BatchNormaliza (None, 8, 8, 512)    2048        encoder_4_1b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 512)    0           encoder_4_1b_shortcut[0][0]      \n",
      "                                                                 encoder_4_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_1b_act (Activation)   (None, 8, 8, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_2a_conv (Conv2D)      (None, 8, 8, 512)    2359808     encoder_4_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_2a_bn (BatchNormaliza (None, 8, 8, 512)    2048        encoder_4_2a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_2a_act (Activation)   (None, 8, 8, 512)    0           encoder_4_2a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_2b_conv (Conv2D)      (None, 8, 8, 512)    2359808     encoder_4_2a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_2b_bn (BatchNormaliza (None, 8, 8, 512)    2048        encoder_4_2b_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 512)    0           encoder_4_1b_act[0][0]           \n",
      "                                                                 encoder_4_2b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4_2b_act (Activation)   (None, 8, 8, 512)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1a_conv (Conv2D)      (None, 8, 8, 128)    65664       encoder_4_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1a_bn (BatchNormaliza (None, 8, 8, 128)    512         decoder_4_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1a_act (Activation)   (None, 8, 8, 128)    0           decoder_4_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1b_fullconv (Conv2DTr (None, 16, 16, 128)  147584      decoder_4_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1b_bn (BatchNormaliza (None, 16, 16, 128)  512         decoder_4_1b_fullconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1b_act (Activation)   (None, 16, 16, 128)  0           decoder_4_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1c_conv (Conv2D)      (None, 16, 16, 256)  33024       decoder_4_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1c_bn (BatchNormaliza (None, 16, 16, 256)  1024        decoder_4_1c_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4_1c_act (Activation)   (None, 16, 16, 256)  0           decoder_4_1c_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 512)  0           decoder_4_1c_act[0][0]           \n",
      "                                                                 encoder_3_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1a_conv (Conv2D)      (None, 16, 16, 64)   32832       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1a_bn (BatchNormaliza (None, 16, 16, 64)   256         decoder_3_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1a_act (Activation)   (None, 16, 16, 64)   0           decoder_3_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1b_fullconv (Conv2DTr (None, 32, 32, 64)   36928       decoder_3_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1b_bn (BatchNormaliza (None, 32, 32, 64)   256         decoder_3_1b_fullconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1b_act (Activation)   (None, 32, 32, 64)   0           decoder_3_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1c_conv (Conv2D)      (None, 32, 32, 128)  8320        decoder_3_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1c_bn (BatchNormaliza (None, 32, 32, 128)  512         decoder_3_1c_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3_1c_act (Activation)   (None, 32, 32, 128)  0           decoder_3_1c_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 256)  0           decoder_3_1c_act[0][0]           \n",
      "                                                                 encoder_2_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1a_conv (Conv2D)      (None, 32, 32, 32)   8224        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1a_bn (BatchNormaliza (None, 32, 32, 32)   128         decoder_2_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1a_act (Activation)   (None, 32, 32, 32)   0           decoder_2_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1b_fullconv (Conv2DTr (None, 64, 64, 32)   9248        decoder_2_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1b_bn (BatchNormaliza (None, 64, 64, 32)   128         decoder_2_1b_fullconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1b_act (Activation)   (None, 64, 64, 32)   0           decoder_2_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1c_conv (Conv2D)      (None, 64, 64, 64)   2112        decoder_2_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1c_bn (BatchNormaliza (None, 64, 64, 64)   256         decoder_2_1c_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2_1c_act (Activation)   (None, 64, 64, 64)   0           decoder_2_1c_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 128)  0           decoder_2_1c_act[0][0]           \n",
      "                                                                 encoder_1_2b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1a_conv (Conv2D)      (None, 64, 64, 16)   2064        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1a_bn (BatchNormaliza (None, 64, 64, 16)   64          decoder_1_1a_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1a_act (Activation)   (None, 64, 64, 16)   0           decoder_1_1a_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1b_fullconv (Conv2DTr (None, 128, 128, 16) 2320        decoder_1_1a_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1b_bn (BatchNormaliza (None, 128, 128, 16) 64          decoder_1_1b_fullconv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1b_act (Activation)   (None, 128, 128, 16) 0           decoder_1_1b_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1c_conv (Conv2D)      (None, 128, 128, 64) 1088        decoder_1_1b_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1c_bn (BatchNormaliza (None, 128, 128, 64) 256         decoder_1_1c_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1_1c_act (Activation)   (None, 128, 128, 64) 0           decoder_1_1c_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "final_1_fullconv (Conv2DTranspo (None, 256, 256, 32) 18464       decoder_1_1c_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "final_1_bn (BatchNormalization) (None, 256, 256, 32) 128         final_1_fullconv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "final__1_act (Activation)       (None, 256, 256, 32) 0           final_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "final_2_conv (Conv2D)           (None, 256, 256, 32) 9248        final__1_act[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_2_bn (BatchNormalization) (None, 256, 256, 32) 128         final_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final__2_act (Activation)       (None, 256, 256, 32) 0           final_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "final_3_fullconv (Conv2DTranspo (None, 512, 512, 1)  129         final__2_act[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 1)  0           final_3_fullconv[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 11,572,961\n",
      "Trainable params: 11,563,041\n",
      "Non-trainable params: 9,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = linknet.build_LinkNet(input_shape=(512,512, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data, Preprocessing, Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "The training dataset consists of 5088 images. Each car is presented in 16 fixed photo angles. The ground truth training mask images were converted from *.gif* to *.png* format so as to be compatible with the *OpenCV* library. \n",
    "\n",
    "The Carvana dataset can be found [here](https://www.kaggle.com/c/carvana-image-masking-challenge/data). The training images and ground truth masks are in the *train* and *train_masks* folders respectively. The test data was not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:50:34.627786Z",
     "start_time": "2017-09-04T16:50:33.936807Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATAPATH+'/train_masks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:50:34.647571Z",
     "start_time": "2017-09-04T16:50:34.629747Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.iloc[2:,:]\n",
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:50:35.817191Z",
     "start_time": "2017-09-04T16:50:35.810931Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_train = df_train['img'].map(lambda s: s.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:50:36.231117Z",
     "start_time": "2017-09-04T16:50:36.225000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_train_split, ids_valid_split = \\\n",
    "    train_test_split(ids_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing -- rescaling (input and mask data)\n",
    "The original image resolution of 1918 x 1280 was downsampled to 512 x 512 using the *OpenCV* library functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:50:33.348138Z",
     "start_time": "2017-09-04T16:50:33.344715Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_width = 512\n",
    "input_height = 512\n",
    "max_epochs = 5\n",
    "orig_width = 1918\n",
    "orig_height= 1280\n",
    "threshold  = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:54:47.383436Z",
     "start_time": "2017-09-04T16:51:01.386483Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_imgs  = {}\n",
    "all_masks = {}\n",
    "\n",
    "for id in ids_train:\n",
    "    img  = cv2.imread(DATAPATH+'/train/{}.jpg'.format(id))\n",
    "    img  = cv2.resize(img, (input_width, input_height))\n",
    "    mask = cv2.imread(DATAPATH+'/train_masks_png/{}_mask.png'.format(id), cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (input_width, input_height))\n",
    "    all_imgs[id]  = img\n",
    "    all_masks[id] = mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation\n",
    "\n",
    "The following transformations using the *OpenCV* library were made:\n",
    "* Hue, Saturation, Value using randomHueSaturationValue\n",
    "* Shift, Scale, Rotate using randomShiftScaleRotate\n",
    "* Horizontal flips using randomHorizontalFlip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:55:10.381921Z",
     "start_time": "2017-09-04T16:55:10.362537Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(train_batch_size):\n",
    "    while True:\n",
    "        this_ids_train_split = random.sample(list(ids_train_split), len(ids_train_split))\n",
    "        for start in range(0, len(ids_train_split), train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + train_batch_size, len(ids_train_split))\n",
    "            ids_train_batch = this_ids_train_split[start:end]\n",
    "            for id in ids_train_batch:\n",
    "                img  = all_imgs[id]\n",
    "                mask = all_masks[id]\n",
    "                img = augmentation.randomHueSaturationValue(img,\n",
    "                                               hue_shift_limit=(-50, 50),\n",
    "                                               sat_shift_limit=(-5, 5),\n",
    "                                               val_shift_limit=(-15, 15))\n",
    "                img, mask = augmentation.randomShiftScaleRotate(img, mask,\n",
    "                                                   shift_limit=(-0.0625, 0.0625),\n",
    "                                                   scale_limit=(-0.1, 0.1),\n",
    "                                                   rotate_limit=(-0, 0))\n",
    "                img, mask = augmentation.randomHorizontalFlip(img, mask)\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:55:11.232951Z",
     "start_time": "2017-09-04T16:55:11.222686Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_generator(val_batch_size):\n",
    "    while True:\n",
    "        for start in range(0, len(ids_valid_split), val_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + val_batch_size, len(ids_valid_split))\n",
    "            ids_valid_batch = ids_valid_split[start:end]\n",
    "            for id in ids_valid_batch.values:\n",
    "                img  = all_imgs[id]\n",
    "                mask = all_masks[id]\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(mask)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            y_batch = np.array(y_batch, np.float32) / 255\n",
    "            yield x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:55:12.717822Z",
     "start_time": "2017-09-04T16:55:12.715003Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 6\n",
    "val_batch_size   = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T19:10:46.231022Z",
     "start_time": "2017-08-23T18:00:39.037950Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 395s - loss: 1.1837 - dice_coef: 0.9106 - val_loss: 0.7282 - val_dice_coef: 0.9767\n",
      "Epoch 2/5\n",
      " - 285s - loss: 0.4947 - dice_coef: 0.9793 - val_loss: 0.3354 - val_dice_coef: 0.9818\n",
      "Epoch 3/5\n",
      " - 285s - loss: 0.2512 - dice_coef: 0.9836 - val_loss: 0.1952 - val_dice_coef: 0.9858\n",
      "Epoch 4/5\n",
      " - 285s - loss: 0.1664 - dice_coef: 0.9857 - val_loss: 0.1435 - val_dice_coef: 0.9874\n",
      "Epoch 5/5\n",
      " - 285s - loss: 0.1319 - dice_coef: 0.9870 - val_loss: 0.1187 - val_dice_coef: 0.9888\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ReduceLROnPlateau(monitor='val_dice_coef',\n",
    "                               factor=0.2,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4,\n",
    "                               mode='max'),\n",
    "             ModelCheckpoint(monitor='val_dice_coef',\n",
    "                             filepath='../weights/best_weights_linknet_1.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='max')]\n",
    "\n",
    "history = model.fit_generator(generator=train_generator(train_batch_size),\n",
    "                    steps_per_epoch=np.ceil(float(len(ids_train_split)) / float(train_batch_size)),\n",
    "                    epochs=max_epochs,\n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_generator(val_batch_size),\n",
    "                    validation_steps=np.ceil(float(len(ids_valid_split)) / float(val_batch_size)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T19:10:46.242155Z",
     "start_time": "2017-08-24T19:10:46.232898Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('../weights/best_weights_linknet_1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T16:55:42.375194Z",
     "start_time": "2017-09-04T16:55:30.907272Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(lr=0.00001), loss=losses.bce_dice_loss, \n",
    "              metrics=[losses.dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 290s - loss: 0.1168 - dice_coef: 0.9888 - val_loss: 0.1137 - val_dice_coef: 0.9897\n",
      "Epoch 2/20\n",
      " - 285s - loss: 0.1136 - dice_coef: 0.9892 - val_loss: 0.1113 - val_dice_coef: 0.9898\n",
      "Epoch 3/20\n",
      " - 285s - loss: 0.1111 - dice_coef: 0.9894 - val_loss: 0.1088 - val_dice_coef: 0.9901\n",
      "Epoch 4/20\n",
      " - 285s - loss: 0.1087 - dice_coef: 0.9897 - val_loss: 0.1066 - val_dice_coef: 0.9902\n",
      "Epoch 5/20\n",
      " - 285s - loss: 0.1066 - dice_coef: 0.9898 - val_loss: 0.1045 - val_dice_coef: 0.9904\n",
      "Epoch 6/20\n",
      " - 285s - loss: 0.1045 - dice_coef: 0.9900 - val_loss: 0.1027 - val_dice_coef: 0.9904\n",
      "Epoch 7/20\n",
      " - 285s - loss: 0.1027 - dice_coef: 0.9900 - val_loss: 0.1009 - val_dice_coef: 0.9905\n",
      "Epoch 8/20\n",
      " - 285s - loss: 0.1009 - dice_coef: 0.9902 - val_loss: 0.0992 - val_dice_coef: 0.9906\n",
      "Epoch 9/20\n",
      " - 285s - loss: 0.0992 - dice_coef: 0.9903 - val_loss: 0.0974 - val_dice_coef: 0.9908\n",
      "Epoch 10/20\n",
      " - 284s - loss: 0.0976 - dice_coef: 0.9904 - val_loss: 0.0962 - val_dice_coef: 0.9907\n",
      "Epoch 11/20\n",
      " - 285s - loss: 0.0961 - dice_coef: 0.9905 - val_loss: 0.0945 - val_dice_coef: 0.9909\n",
      "Epoch 12/20\n",
      " - 286s - loss: 0.0945 - dice_coef: 0.9906 - val_loss: 0.0932 - val_dice_coef: 0.9909\n",
      "Epoch 13/20\n",
      " - 285s - loss: 0.0930 - dice_coef: 0.9907 - val_loss: 0.0916 - val_dice_coef: 0.9911\n",
      "Epoch 14/20\n",
      " - 285s - loss: 0.0916 - dice_coef: 0.9908 - val_loss: 0.0905 - val_dice_coef: 0.9911\n",
      "Epoch 15/20\n",
      " - 285s - loss: 0.0903 - dice_coef: 0.9909 - val_loss: 0.0890 - val_dice_coef: 0.9912\n",
      "Epoch 16/20\n",
      " - 284s - loss: 0.0889 - dice_coef: 0.9909 - val_loss: 0.0880 - val_dice_coef: 0.9911\n",
      "Epoch 17/20\n",
      " - 285s - loss: 0.0878 - dice_coef: 0.9909 - val_loss: 0.0865 - val_dice_coef: 0.9913\n",
      "Epoch 18/20\n",
      " - 285s - loss: 0.0865 - dice_coef: 0.9911 - val_loss: 0.0853 - val_dice_coef: 0.9914\n",
      "Epoch 19/20\n",
      " - 285s - loss: 0.0853 - dice_coef: 0.9911 - val_loss: 0.0842 - val_dice_coef: 0.9914\n",
      "Epoch 20/20\n",
      " - 284s - loss: 0.0841 - dice_coef: 0.9912 - val_loss: 0.0833 - val_dice_coef: 0.9914\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ReduceLROnPlateau(monitor='val_dice_coef',\n",
    "                               factor=0.2,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4,\n",
    "                               mode='max'),\n",
    "             ModelCheckpoint(monitor='val_dice_coef',\n",
    "                             filepath='../weights/best_weights_linknet_1.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='max')]\n",
    "\n",
    "history = model.fit_generator(generator=train_generator(train_batch_size),\n",
    "                    steps_per_epoch=np.ceil(float(len(ids_train_split)) / float(train_batch_size)),\n",
    "                    epochs=max_epochs,\n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_generator(val_batch_size),\n",
    "                    validation_steps=np.ceil(float(len(ids_valid_split)) / float(val_batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f25388cbbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "\n",
    "The LinkNet was designed to be efficient for real-time semantic segmentation applications, i.e. to obtain near state-of-the-art scores without compromising processing time. In this run, each epoch took ~4-5 minutes with a NVIDIA Tesla K80 GPU. This is an order of magnitude faster than several custom U-Net models that were run using the same dataset/image resolution (the U-Net models took 40-50 mins/epoch). The U-Net models ranged from 3.6 - 8.5 million parameters; the LinkNet has 11.6 million parameters so in terms of processing time the LinkNet is a clear winner.   \n",
    "In terms of the accuracy, while the U-Net models performed very well in the Carvana challenge, some of the top entries (the [first](http://blog.kaggle.com/2017/12/22/carvana-image-masking-first-place-interview/?utm_medium=social&utm_source=twitter.com&utm_campaign=carvana+winners+interview) and sixth place winners) used an ensemble of both U-Net and LinkNet models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Further Reading \n",
    "\n",
    "<a name=\"ref1\"></a>[1] [Chaurasia, Abhishek, Culurciello, Eugenio. \"LinkNet: Exploiting Encoder Representations for Efficient Semantic Segmentation.\" arXiv:1707.03718v1(cs.CV)](https://arxiv.org/pdf/1707.03718.pdf)  \n",
    "\n",
    "<a name=\"ref2\"></a>[2] [He, Kaiming et al. \"Deep Residual Learning for Image Recognition.\" arXiv:1512.03385 [cs.CV]](https://arxiv.org/pdf/1512.03385.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background-color: #FAAC58; margin-left: 0px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px;\">\n",
    "\n",
    "\n",
    "Author:  Meena Mani  <br>\n",
    "Email:   meenas.mailbag@gmail.com   <br> \n",
    "Twitter: @meena_uvaca    <br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
